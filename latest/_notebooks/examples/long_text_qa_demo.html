
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" sizes="16x16" href="../../_static/images/favicon/favicon-16x16.png" type="image/png">
    <link rel="icon" sizes="32x32" href="../../_static/images/favicon/favicon-32x32.png" type="image/png">
    <link rel="apple-touch-icon" sizes="180x180" href="../../_static/images/favicon/apple-touch-icon.png" type="image/png">
    <title>üéØ Claim-QA Uncertainty Quantification (Long-Text) &#8212; uqlm 0.5 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=662d8ef6" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=db78e746"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "displayMath": [["$$", "$$"], ["\\[", "\\]"]]}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_notebooks/examples/long_text_qa_demo';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://cvs-health.github.io/uqlm/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.5';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/horizontal_logo.png" class="logo__image only-light" alt="uqlm 0.5 documentation - Home"/>
    <img src="../../_static/horizontal_logo_no_bg.png" class="logo__image only-dark pst-js-only" alt="uqlm 0.5 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../scorer_definitions/index.html">
    Scorer Definitions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../scorer_definitions/index.html">
    Scorer Definitions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">üéØ Claim-QA Uncertainty Quantification (Long-Text)</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="üéØ-Claim-QA-Uncertainty-Quantification-(Long-Text)">
<h1>üéØ Claim-QA Uncertainty Quantification (Long-Text)<a class="headerlink" href="#üéØ-Claim-QA-Uncertainty-Quantification-(Long-Text)" title="Link to this heading">#</a></h1>
<div style="background-color: rgba(200, 200, 200, 0.1); padding: 20px; border-radius: 8px; margin-bottom: 20px; border: 1px solid rgba(127, 127, 127, 0.2); max-width: 97.5%; overflow-wrap: break-word;"><p style="font-size: 16px; line-height: 1.6"><p>Claim-QA scorers, adapted as a generalization of long-form semantic entropy, are another method for detecting claim-level or sentence-level hallucinations in long-form LLM outputs. These scorers implement the following steps: decompose responses into granular units (sentences or claims), convert each claim or sentence to a question, sample LLM responses to those questions, and measure consistency among those answers to score the claim. The available scorers and papers from which they are adapted
are below:</p>
</p><ul class="simple">
<li><p>Long-form Semantic Entropy (<a class="reference external" href="https://www.nature.com/articles/s41586-024-07421-0">Farquhar et al., 2024</a>)</p></li>
<li><p>Black-Box Generalizations of Long-form Semantic Entropy</p></li>
</ul>
</div><section id="üìä-What-You'll-Do-in-This-Demo">
<h2>üìä What You‚Äôll Do in This Demo<a class="headerlink" href="#üìä-What-You'll-Do-in-This-Demo" title="Link to this heading">#</a></h2>
<div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>1</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Set up LLM and prompts.</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Set up LLM instance and load example data prompts.</p>
</p></div></div><div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>2</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Generate LLM Responses and Confidence Scores</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Generate responses and compute claim-level confidence scores using the LongTextQA() class.</p>
</p></div></div><div style="display: flex; margin-bottom: 25px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>3</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Evaluate Hallucination Detection Performance</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Grade claims with <code class="docutils literal notranslate"><span class="pre">FactScoreGrader</span></code> class and evaluate claim-level hallucination detection.</p>
</p></div></div></section>
<section id="‚öñÔ∏è-Advantages-&amp;-Limitations">
<h2>‚öñÔ∏è Advantages &amp; Limitations<a class="headerlink" href="#‚öñÔ∏è-Advantages-&-Limitations" title="Link to this heading">#</a></h2>
<div style="display: flex; gap: 20px"><div style="flex: 1; background-color: rgba(0, 200, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(0, 200, 0, 0.2)"><h3 style="color: #2e8b57; margin-top: 0"><p>Pros</p>
</h3><ul style="margin-bottom: 0"><li><p>Universal Compatibility: Works with any LLM without requiring token probability access</p>
</li><li><p>Fine-Grained Scoring: Score at sentence or claim-level to localize likely hallucinations</p>
</li><li><p>Uncertainty-aware decoding: Improve factual precision by dropping high-uncertainty claims</p>
</li></ul></div><div style="flex: 1; background-color: rgba(200, 0, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(200, 0, 0, 0.2)"><h3 style="color: #b22222; margin-top: 0"><p>Cons</p>
</h3><ul style="margin-bottom: 0"><li><p>Higher Cost: Requires multiple generations per prompt</p>
</li><li><p>Slower: Multiple generations and comparison calculations increase latency</p>
</li><li><p>Complex: More complex than simpler methods offered by <code class="docutils literal notranslate"><span class="pre">LongTextUQ</span></code>.</p>
</li></ul></div></div><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LongTextQA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_example_dataset</span><span class="p">,</span> <span class="n">display_response_refinement</span><span class="p">,</span> <span class="n">claims_dicts_to_lists</span><span class="p">,</span> <span class="n">plot_model_accuracies</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm.longform</span><span class="w"> </span><span class="kn">import</span> <span class="n">FactScoreGrader</span>
</pre></div>
</div>
</div>
</section>
<section id="1.-Set-up-LLM-and-Prompts">
<h2>1. Set up LLM and Prompts<a class="headerlink" href="#1.-Set-up-LLM-and-Prompts" title="Link to this heading">#</a></h2>
<p>In this demo, we will illustrate this approach using the <a class="reference external" href="https://github.com/shmsw25/FActScore/tree/main/factscore">FactScore</a> longform QA dataset. To implement with your use case, simply <strong>replace the example prompts with your data</strong>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load example dataset (FactScore)</span>
<span class="n">factscore</span> <span class="o">=</span> <span class="n">load_example_dataset</span><span class="p">(</span><span class="s2">&quot;factscore&quot;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">15</span><span class="p">)[[</span><span class="s2">&quot;hundredw_prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;wikipedia_text&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;hundredw_prompt&quot;</span><span class="p">:</span> <span class="s2">&quot;prompt&quot;</span><span class="p">})</span>
<span class="n">factscore</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading dataset - factscore...
Processing dataset...
Dataset ready!
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>wikipedia_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Tell me a bio of Suthida within 100 words.\n</td>
      <td>Suthida Bajrasudhabimalalakshana (Thai: ‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Tell me a bio of Miguel √Ångel F√©lix Gallardo w...</td>
      <td>Miguel √Ångel F√©lix Gallardo (born January 8, 1...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Tell me a bio of Iggy Azalea within 100 words.\n</td>
      <td>Amethyst Amelia Kelly (born 7 June 1990), know...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Tell me a bio of Fernando da Costa Novaes with...</td>
      <td>Fernando da Costa Novaes (April 6, 1927 ‚Äì Marc...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Tell me a bio of Jan Zamoyski within 100 words.\n</td>
      <td>Jan Sariusz Zamoyski (Latin: Ioannes Zamoyski ...</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>In this example, we use <code class="docutils literal notranslate"><span class="pre">ChatVertexAI</span></code> to instantiate our LLM, but any <a class="reference external" href="https://js.langchain.com/docs/integrations/chat/">LangChain Chat Model</a> may be used. Be sure to <strong>replace with your LLM of choice.</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_google_vertexai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatVertexAI</span>

<span class="n">gemini_flash</span> <span class="o">=</span> <span class="n">ChatVertexAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gemini-2.5-flash&quot;</span><span class="p">)</span>
<span class="n">gemini_flash_lite</span> <span class="o">=</span> <span class="n">ChatVertexAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gemini-2.5-flash-lite&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="2.-Generate-LLM-Responses-and-Claim/Sentence-Level-Confidence-Scores">
<h2>2. Generate LLM Responses and Claim/Sentence-Level Confidence Scores<a class="headerlink" href="#2.-Generate-LLM-Responses-and-Claim/Sentence-Level-Confidence-Scores" title="Link to this heading">#</a></h2>
<section id="LongTextQA()---Generate-long-text-LLM-responses,-decompose-into-claims-or-sentences,-create-questions-for-which-those-claims-are-the-answers,-and-measure-consistency-in-LLM-responses-to-those-questions.">
<h3><code class="docutils literal notranslate"><span class="pre">LongTextQA()</span></code> - Generate long-text LLM responses, decompose into claims or sentences, create questions for which those claims are the answers, and measure consistency in LLM responses to those questions.<a class="headerlink" href="#LongTextQA()---Generate-long-text-LLM-responses,-decompose-into-claims-or-sentences,-create-questions-for-which-those-claims-are-the-answers,-and-measure-consistency-in-LLM-responses-to-those-questions." title="Link to this heading">#</a></h3>
<p><img alt="Sample Image" src="https://raw.githubusercontent.com/cvs-health/uqlm/develop/assets/images/uad_graphic.png" /></p>
<section id="üìã-Class-Attributes">
<h4>üìã Class Attributes<a class="headerlink" href="#üìã-Class-Attributes" title="Link to this heading">#</a></h4>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 20%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Parameter</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Type &amp; Default</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 55%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description</p>
</th></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>llm</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BaseChatModeldefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>A langchain llm <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code>. User is responsible for specifying temperature and other relevant parameters to the constructor of the provided <code class="docutils literal notranslate"><span class="pre">llm</span></code> object.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>granularity</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>strdefault=‚Äùclaim‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies whether to decompose and score at claim or sentence level granularity. Must be either ‚Äúclaim‚Äù or ‚Äúsentence‚Äù.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>scorers</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>List[str]default=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies which black box (consistency) scorers to include. Must be subset of [‚Äòsemantic_negentropy‚Äô, ‚Äònoncontradiction‚Äô, ‚Äòexact_match‚Äô, ‚Äòbert_score‚Äô, ‚Äòcosine_sim‚Äô, ‚Äòentailment‚Äô, ‚Äòsemantic_sets_confidence‚Äô]. If None, defaults to [‚Äúentailment‚Äù].</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>aggregation</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>strdefault=‚Äùmean‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies how to aggregate claim/sentence-level scores to response-level scores. Must be one of ‚Äòmin‚Äô or ‚Äòmean‚Äô.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>response_refinement</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>booldefault=False</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies whether to refine responses with uncertainty-aware decoding. This approach removes claims with confidence scores below the response_refinement_threshold and uses the claim_decomposition_llm to reconstruct the response from the retained claims. For more details, refer to Jiang et al., 2024: <a class="reference external" href="https://arxiv.org/abs/2410.20783">https://arxiv.org/abs/2410.20783</a></p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>claim_filtering_scorer</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Optional[str]default=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies which scorer to use to filter claims if response_refinement is True. If not provided, defaults to the first element of self.scorers.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>claim_decomposition_llm</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BaseChatModeldefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>A langchain llm <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code> to be used for decomposing responses into individual claims. Also used for claim refinement. If granularity=‚Äùclaim‚Äù and claim_decomposition_llm is None, the provided <code class="docutils literal notranslate"><span class="pre">llm</span></code> will be used for claim decomposition.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>question_generator_llm</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BaseChatModeldefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>A langchain llm <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code> to be used for decomposing responses into individual claims. Used for generating questions from claims or sentences in claim-QA approach. If None, defaults to claim_decomposition_llm.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>device</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>str or torch.devicedefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies the device that NLI model use for prediction. If None, detects and returns the best available PyTorch device. Prioritizes CUDA (NVIDIA GPU), then MPS (macOS), then CPU.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>system_prompt</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>str or Nonedefault=‚ÄùYou are a helpful assistant.‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Optional argument for user to provide custom system prompt for the LLM.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>max_calls_per_min</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>intdefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies how many API calls to make per minute to avoid rate limit errors. By default, no limit is specified.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>use_n_param</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>booldefault=False</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies whether to use n parameter for BaseChatModel. Not compatible with all BaseChatModel classes. If used, it speeds up the generation process substantially when num_responses is large.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>sampling_temperature</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>floatdefault=1</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>The ‚Äòtemperature‚Äô parameter for LLM to use when generating sampled LLM responses. Must be greater than 0.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>nli_model_name</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>strdefault=‚Äùmicrosoft/deberta-large-mnli‚Äù</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies which NLI model to use. Must be acceptable input to AutoTokenizer.from_pretrained() and AutoModelForSequenceClassification.from_pretrained().</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>max_length</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>intdefault=2000</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies the maximum allowed string length for LLM responses for NLI computation. Responses longer than this value will be truncated in NLI computations to avoid OutOfMemoryError.</p>
</td></tr></table></section>
<section id="üîç-Parameter-Groups">
<h4>üîç Parameter Groups<a class="headerlink" href="#üîç-Parameter-Groups" title="Link to this heading">#</a></h4>
<div style="display: flex; gap: 20px; margin-bottom: 20px"><div style="flex: 1; padding: 10px; background-color: rgba(0, 100, 200, 0.1); border-radius: 5px; border: 1px solid rgba(0, 100, 200, 0.2);"><p style="font-weight: bold"><p>üß† LLM-Specific</p>
</p><ul><li><p>llm</p>
</li><li><p>system_prompt</p>
</li><li><p>sampling_temperature</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(0, 200, 0, 0.1); border-radius: 5px; border: 1px solid rgba(0, 200, 0, 0.2);"><p style="font-weight: bold"><p>üìä Confidence Scores</p>
</p><ul><li><p>granularity</p>
</li><li><p>scorers</p>
</li><li><p>aggregation</p>
</li><li><p>num_questions</p>
</li><li><p>num_claim_qa_responses</p>
</li><li><p>response_refinement</p>
</li><li><p>response_refinement_threshold</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(200, 150, 0, 0.1); border-radius: 5px; border: 1px solid rgba(200, 150, 0, 0.2);"><p style="font-weight: bold"><p>üñ•Ô∏è Hardware</p>
</p><ul><li><p>device</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(200, 0, 200, 0.1); border-radius: 5px; border: 1px solid rgba(200, 0, 200, 0.2);"><p style="font-weight: bold"><p>‚ö° Performance</p>
</p><ul><li><p>max_calls_per_min</p>
</li><li><p>use_n_param</p>
</li></ul></div></div><p>```</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">claimqa</span> <span class="o">=</span> <span class="n">LongTextQA</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">gemini_flash</span><span class="p">,</span>
    <span class="n">question_generator_llm</span><span class="o">=</span><span class="n">gemini_flash</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>  <span class="c1"># switch to &#39;min&#39; for more conservative scoring</span>
    <span class="n">response_refinement</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># whether to filter out low-confidence claims</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;noncontradiction&quot;</span><span class="p">],</span>
    <span class="c1"># max_calls_per_min=1000,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
claim_filtering_scorer is not specified for response_refinement. Defaulting to noncontradiction.
</pre></div></div>
</div>
</section>
</section>
<section id="üîÑ-Class-Methods">
<h3>üîÑ Class Methods<a class="headerlink" href="#üîÑ-Class-Methods" title="Link to this heading">#</a></h3>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Method</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 75%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description &amp; Parameters</p>
</th></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BlackBoxUQ.generate_and_score</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Generate LLM responses, sampled LLM (candidate) responses, and compute confidence scores for the provided prompts.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>prompts - (List[str] or List[List[BaseMessage]]) A list of input prompts for the model.</p>
</li><li><p>num_questions - (int, default=2) Specifies how many questions to generate per claim/sentence.</p>
</li><li><p>num_claim_qa_responses - (int, default=5) Specifies how many sampled responses to generate per claim/sentence question.</p>
</li><li><p>response_refinement_threshold - (float, default=1/3) Threshold for uncertainty-aware filtering. Claims with confidence scores below this threshold are dropped from the refined response. Only used if response_refinement is True.</p>
</li><li><p>show_progress_bars - (bool, default=True) If True, displays a progress bar while generating and scoring responses.</p>
</li></ul><p><p>Returns: UQResult containing data (prompts, responses, sampled responses, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>üí° Best For: Complete end-to-end uncertainty quantification when starting with prompts.</p>
</div></td></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BlackBoxUQ.score</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Compute confidence scores on provided LLM responses. Should only be used if responses and sampled responses are already generated.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>prompts - (List[str]) A list of input prompts for the model.</p>
</li><li><p>responses - (List[str]) A list of LLM responses for the prompts.</p>
</li><li><p>num_questions - (int, default=2) Specifies how many questions to generate per claim/sentence.</p>
</li><li><p>num_claim_qa_responses - (int, default=5) Specifies how many sampled responses to generate per claim/sentence question.</p>
</li><li><p>response_refinement_threshold - (float, default=1/3) Threshold for uncertainty-aware filtering. Claims with confidence scores below this threshold are dropped from the refined response. Only used if response_refinement is True.</p>
</li><li><p>show_progress_bars - (bool, default=True) If True, displays a progress bar while scoring responses.</p>
</li></ul><p><p>Returns: UQResult containing data (responses, sampled responses, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>üí° Best For: Computing uncertainty scores when responses are already generated elsewhere.</p>
</div></td></tr></table><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">claimqa</span><span class="o">.</span><span class="n">generate_and_score</span><span class="p">(</span><span class="n">prompts</span><span class="o">=</span><span class="n">factscore</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">to_list</span><span class="p">(),</span> <span class="n">response_refinement_threshold</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e3093a401fcc4953bc1ad58d260af874", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result_df</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>response</th>
      <th>noncontradiction</th>
      <th>claims_data</th>
      <th>refined_response</th>
      <th>refined_noncontradiction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Tell me a bio of Suthida within 100 words.\n</td>
      <td>Queen Suthida Bajrasudhabimalalakshana is the ...</td>
      <td>0.872727</td>
      <td>[{'claim': 'Queen Suthida Bajrasudhabimalalaks...</td>
      <td>Queen Suthida Bajrasudhabimalalakshana, the cu...</td>
      <td>0.985608</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Tell me a bio of Miguel √Ångel F√©lix Gallardo w...</td>
      <td>Miguel √Ångel F√©lix Gallardo, known as "El Padr...</td>
      <td>0.922575</td>
      <td>[{'claim': 'Miguel √Ångel F√©lix Gallardo was kn...</td>
      <td>Miguel √Ångel F√©lix Gallardo, famously known as...</td>
      <td>0.973158</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Tell me a bio of Iggy Azalea within 100 words.\n</td>
      <td>Amethyst Amelia Kelly, known professionally as...</td>
      <td>0.895390</td>
      <td>[{'claim': 'Amethyst Amelia Kelly is known pro...</td>
      <td>Amethyst Amelia Kelly, known professionally as...</td>
      <td>0.986233</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Tell me a bio of Fernando da Costa Novaes with...</td>
      <td>Fernando da Costa Novaes (1942-2004) was a hig...</td>
      <td>0.797684</td>
      <td>[{'claim': 'Fernando da Costa Novaes was born ...</td>
      <td>Fernando da Costa Novaes was a highly influent...</td>
      <td>0.966738</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Tell me a bio of Jan Zamoyski within 100 words.\n</td>
      <td>Jan Zamoyski (1542‚Äì1605) was a preeminent Poli...</td>
      <td>0.947813</td>
      <td>[{'claim': 'Jan Zamoyski was born in 1542.', '...</td>
      <td>Jan Zamoyski, born in 1542 and dying in 1605, ...</td>
      <td>0.978016</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<section id="Response-refinement">
<h4>Response refinement<a class="headerlink" href="#Response-refinement" title="Link to this heading">#</a></h4>
<p>Response refinement works by dropping claims with confidence scores (specified with <code class="docutils literal notranslate"><span class="pre">claim_filtering_scorer</span></code>) below a specified threshold (specified with <code class="docutils literal notranslate"><span class="pre">response_refinement_threshold</span></code>) and reconstructing the response from the retained claims.</p>
<p><img alt="Sample Image" src="https://raw.githubusercontent.com/cvs-health/uqlm/develop/assets/images/uad_graphic.png" /></p>
<p>To illustrate how the response refinement operates, let‚Äôs view an example. We first view the fine-grained claim-level data, including the claims in the original response, the claim-level confidence scores, and whether each claim was removed during the response refinement process.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># View fine-grained claim data for a response</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">claims_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[{&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana is the current Queen of Thailand.&#39;,
  &#39;removed&#39;: False,
  &#39;claim_questions&#39;: [&#39;Who is the current Queen of Thailand?&#39;],
  &#39;claim_qa_responses&#39;: [&#39;Suthida.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Suthida.&#39;,
    &#39;Suthida.&#39;,
    &#39;Suthida.&#39;,
    &#39;Suthida.&#39;,
    &#39;Suthida&#39;]],
  &#39;noncontradiction&#39;: 0.997577428817749},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana was born Suthida Tidjai.&#39;,
  &#39;removed&#39;: True,
  &#39;claim_questions&#39;: [&#34;What was Queen Suthida Bajrasudhabimalalakshana&#39;s birth name?&#34;],
  &#39;claim_qa_responses&#39;: [&#39;Suthida Tidjai&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Nui-Ngam&#39;,
    &#39;Suthida Tidjai&#39;,
    &#39;Suthida Tidjai&#39;,
    &#39;Suthida Tidjai&#39;,
    &#39;Suthida Tidjai&#39;]],
  &#39;noncontradiction&#39;: 0.8045254647731781},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana began her career as a flight attendant.&#39;,
  &#39;removed&#39;: False,
  &#39;claim_questions&#39;: [&#34;What was Queen Suthida Bajrasudhabimalalakshana&#39;s first career?&#34;],
  &#39;claim_qa_responses&#39;: [&#39;Flight attendant.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Flight attendant.&#39;,
    &#39;Flight attendant.&#39;,
    &#39;Flight attendant.&#39;,
    &#39;Flight attendant.&#39;,
    &#39;Flight attendant.&#39;]],
  &#39;noncontradiction&#39;: 1.0},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana was a flight attendant for Thai Airways International.&#39;,
  &#39;removed&#39;: False,
  &#39;claim_questions&#39;: [&#34;Identify the exact statement detailing Queen Suthida Bajrasudhabimalalakshana&#39;s previous occupation and employer.&#34;],
  &#39;claim_qa_responses&#39;: [&#39;She was a flight attendant for Thai Airways.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;She was previously a flight attendant for Thai Airways International.&#39;,
    &#39;She previously worked as a flight attendant for Thai Airways.&#39;,
    &#39;She was a flight attendant for Thai Airways.&#39;,
    &#39;She was a flight attendant for Thai Airways.&#39;,
    &#39;Flight attendant for Thai Airways.&#39;]],
  &#39;noncontradiction&#39;: 0.9993116140365601},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana joined the Royal Thai Army.&#39;,
  &#39;removed&#39;: True,
  &#39;claim_questions&#39;: [&#34;What was Queen Suthida Bajrasudhabimalalakshana&#39;s initial involvement with the Royal Thai Army?&#34;],
  &#39;claim_qa_responses&#39;: [&#39;She was commissioned as a second lieutenant in 2010.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Flight attendant.&#39;,
    &#39;Royal Guard.&#39;,
    &#39;Flight attendant for Thai Airways.&#39;,
    &#39;Joined as an officer.&#39;,
    &#39;She joined in 2010 as a second lieutenant.&#39;]],
  &#39;noncontradiction&#39;: 0.72225404},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana rose through the ranks of the Royal Thai Army.&#39;,
  &#39;removed&#39;: True,
  &#39;claim_questions&#39;: [&#34;What particular career trajectory characterized Queen Suthida Bajrasudhabimalalakshana&#39;s involvement in the Royal Thai Army?&#34;],
  &#39;claim_qa_responses&#39;: [&#34;From flight attendant to rapid military promotion, ultimately becoming a general leading the King&#39;s security.&#34;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Rapid promotions as a royal bodyguard.&#39;,
    &#34;From Royal Thai Army officer to General and Deputy Commander of the King&#39;s Guard.&#34;,
    &#39;Joined Royal Thai Army, rapidly rose through ranks to become a general in the Royal Guard.&#39;,
    &#34;Officer to general, commanding the King&#39;s Guard Special Operations Unit.&#34;,
    &#34;Rapid ascent: bodyguard to General and commander in the King&#39;s Guard.&#34;]],
  &#39;noncontradiction&#39;: 0.65020025},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana served in the Royal Security Command.&#39;,
  &#39;removed&#39;: True,
  &#39;claim_questions&#39;: [&#34;What is the claim asserting Queen Suthida Bajrasudhabimalalakshana&#39;s service within the Royal Security Command?&#34;],
  &#39;claim_qa_responses&#39;: [&#39;Commander of the Royal Security Command.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Commander of the Royal Security Command.&#39;,
    &#39;Commander of the Royal Security Command.&#39;,
    &#39;Royal Guard.&#39;,
    &#39;Deputy Commander of the Royal Security Command.&#39;,
    &#39;Commander.&#39;]],
  &#39;noncontradiction&#39;: 0.7191060900688171},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana was made a full General in 2017.&#39;,
  &#39;removed&#39;: False,
  &#39;claim_questions&#39;: [&#34;What is the exact claim describing Queen Suthida Bajrasudhabimalalakshana&#39;s military promotion to a full General in 2017?&#34;],
  &#39;claim_qa_responses&#39;: [&#39;Promoted to General.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Appointed General.&#39;,
    &#39;She was appointed Commander of the Royal Security Command as a General in October 2017.&#39;,
    &#39;No such claim exists for 2017; she was promoted to General in December 2016.&#39;,
    &#39;Appointed a full General.&#39;,
    &#39;Promoted to a full General in December 2017.&#39;]],
  &#39;noncontradiction&#39;: 0.96347487},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana became a consort to King Vajiralongkorn.&#39;,
  &#39;removed&#39;: True,
  &#39;claim_questions&#39;: [&#34;What exact declaration details Queen Suthida Bajrasudhabimalalakshana&#39;s assumption of a regal spousal role alongside King Vajiralongkorn?&#34;],
  &#39;claim_qa_responses&#39;: [&#39;Royal Decree of May 1, 2019.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Royal proclamation on May 1, 2019, declaring her Queen Consort.&#39;,
    &#39;Royal Gazette, May 1, 2019, announcing her marriage to King Vajiralongkorn and elevation to Queen.&#39;,
    &#39;Royal Command of May 1, 2019.&#39;,
    &#39;Royal Gazette declaration, May 1, 2019.&#39;,
    &#39;Royal decree announcing her marriage and elevation to Queen, May 1, 2019, published in the *Royal Gazette*.&#39;]],
  &#39;noncontradiction&#39;: 0.81256753},
 {&#39;claim&#39;: &#39;King Vajiralongkorn is also known as Rama X.&#39;,
  &#39;removed&#39;: True,
  &#39;claim_questions&#39;: [&#39;Provide the full statement that identifies King Vajiralongkorn by his most commonly used regnal name.&#39;],
  &#39;claim_qa_responses&#39;: [&#39;Maha Vajiralongkorn Phra Vajiraklaochaoyuhua.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Maha Vajiralongkorn Phra Vajiraklaochaoyuhua&#39;,
    &#39;King Rama X.&#39;,
    &#39;King Rama X&#39;,
    &#39;Maha Vajiralongkorn Phra Vajiraklaochaoyuhua.&#39;,
    &#39;Maha Vajiralongkorn Phra Vajiraklaochaoyuhua.&#39;]],
  &#39;noncontradiction&#39;: 0.7375492095947266},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana married King Vajiralongkorn on May 1, 2019.&#39;,
  &#39;removed&#39;: False,
  &#39;claim_questions&#39;: [&#39;State the full and accurate declaration regarding the marriage of Queen Suthida Bajrasudhabimalalakshana to King Vajiralongkorn on May 1, 2019.&#39;],
  &#39;claim_qa_responses&#39;: [&#39;Queen Suthida Bajrasudhabimalalakshana married King Vajiralongkorn on May 1, 2019.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Queen Suthida Bajrasudhabimalalakshana married King Vajiralongkorn on May 1, 2019.&#39;,
    &#39;Queen Suthida Bajrasudhabimalalakshana married King Vajiralongkorn on May 1, 2019.&#39;,
    &#39;They officially married on May 1, 2019, making her Queen Suthida Bajrasudhabimalalakshana.&#39;,
    &#39;Suthida was declared Queen Consort and married to King Vajiralongkorn on May 1, 2019.&#39;,
    &#39;Queen Suthida Bajrasudhabimalalakshana married King Vajiralongkorn on May 1, 2019.&#39;]],
  &#39;noncontradiction&#39;: 0.9993778228759765},
 {&#39;claim&#39;: &#34;Queen Suthida Bajrasudhabimalalakshana became Queen just days before King Vajiralongkorn&#39;s official coronation.&#34;,
  &#39;removed&#39;: False,
  &#39;claim_questions&#39;: [&#34;How did the timing of Queen Suthida Bajrasudhabimalalakshana becoming Queen relate to King Vajiralongkorn&#39;s official coronation?&#34;],
  &#39;claim_qa_responses&#39;: [&#39;Shortly before.&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Days before.&#39;,
    &#39;Days before.&#39;,
    &#39;Days before.&#39;,
    &#39;She was appointed Queen days *before* his official coronation.&#39;,
    &#39;She was proclaimed Queen days before his coronation.&#39;]],
  &#39;noncontradiction&#39;: 0.983033},
 {&#39;claim&#39;: &#39;Queen Suthida Bajrasudhabimalalakshana is an influential figure in the Thai monarchy.&#39;,
  &#39;removed&#39;: False,
  &#39;claim_questions&#39;: [&#34;Which statement about Queen Suthida Bajrasudhabimalalakshana&#39;s role in the Thai monarchy declares her to be an influential figure?&#34;],
  &#39;claim_qa_responses&#39;: [&#39;&#34;She holds the rank of General in the Royal Thai Army.&#34;&#39;],
  &#39;claim_qa_sampled_responses&#39;: [[&#39;Key figure.&#39;,
    &#34;Commander of the King&#39;s Royal Guard.&#34;,
    &#39;She plays a pivotal role in the monarchy.&#39;,
    &#39;She is an influential figure in the Thai monarchy.&#39;,
    &#39;&#34;Influential figure&#34; implies active participation or significant impact.&#39;]],
  &#39;noncontradiction&#39;: 0.9564784}]
</pre></div></div>
</div>
<p>We can examine a particular claim in the response that was removed because its confidence score was too low. Let‚Äôs see how this is reflected in the original vs. the refined response.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_response_refinement</span><span class="p">(</span><span class="n">original_text</span><span class="o">=</span><span class="n">result_df</span><span class="o">.</span><span class="n">response</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">claims_data</span><span class="o">=</span><span class="n">result_df</span><span class="o">.</span><span class="n">claims_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">refined_text</span><span class="o">=</span><span class="n">result_df</span><span class="o">.</span><span class="n">refined_response</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #000000; text-decoration-color: #000000; font-weight: bold">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
</pre></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">                                            <span style="color: #000000; text-decoration-color: #000000; font-weight: bold">Response Refinement Example</span>
</pre></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #000000; text-decoration-color: #000000; font-weight: bold">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
</pre></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">
</pre></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #808000; text-decoration-color: #808000">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">Original Response</span><span style="color: #808000; text-decoration-color: #808000"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>
<span style="color: #808000; text-decoration-color: #808000">‚îÇ</span> Queen Suthida Bajrasudhabimalalakshana is the current Queen of Thailand. Born Suthida Tidjai, she began her     <span style="color: #808000; text-decoration-color: #808000">‚îÇ</span>
<span style="color: #808000; text-decoration-color: #808000">‚îÇ</span> career as a flight attendant for Thai Airways International. She later joined the Royal Thai Army, rising       <span style="color: #808000; text-decoration-color: #808000">‚îÇ</span>
<span style="color: #808000; text-decoration-color: #808000">‚îÇ</span> through its ranks, and served in the Royal Security Command. In 2017, she was made a full General. She became a <span style="color: #808000; text-decoration-color: #808000">‚îÇ</span>
<span style="color: #808000; text-decoration-color: #808000">‚îÇ</span> consort to King Vajiralongkorn (Rama X) and married him on May 1, 2019, becoming Queen just days before his     <span style="color: #808000; text-decoration-color: #808000">‚îÇ</span>
<span style="color: #808000; text-decoration-color: #808000">‚îÇ</span> official coronation. She is an influential figure in the Thai monarchy.                                         <span style="color: #808000; text-decoration-color: #808000">‚îÇ</span>
<span style="color: #808000; text-decoration-color: #808000">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>
</pre></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800000; text-decoration-color: #800000">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style="color: #800000; text-decoration-color: #800000; font-weight: bold">Low-Confidence Claims to be Removed</span><span style="color: #800000; text-decoration-color: #800000"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>
<span style="color: #800000; text-decoration-color: #800000">‚îÇ</span> ‚Ä¢ Queen Suthida Bajrasudhabimalalakshana was born Suthida Tidjai.                                               <span style="color: #800000; text-decoration-color: #800000">‚îÇ</span>
<span style="color: #800000; text-decoration-color: #800000">‚îÇ</span> ‚Ä¢ Queen Suthida Bajrasudhabimalalakshana joined the Royal Thai Army.                                            <span style="color: #800000; text-decoration-color: #800000">‚îÇ</span>
<span style="color: #800000; text-decoration-color: #800000">‚îÇ</span> ‚Ä¢ Queen Suthida Bajrasudhabimalalakshana rose through the ranks of the Royal Thai Army.                         <span style="color: #800000; text-decoration-color: #800000">‚îÇ</span>
<span style="color: #800000; text-decoration-color: #800000">‚îÇ</span> ‚Ä¢ Queen Suthida Bajrasudhabimalalakshana served in the Royal Security Command.                                  <span style="color: #800000; text-decoration-color: #800000">‚îÇ</span>
<span style="color: #800000; text-decoration-color: #800000">‚îÇ</span> ‚Ä¢ Queen Suthida Bajrasudhabimalalakshana became a consort to King Vajiralongkorn.                               <span style="color: #800000; text-decoration-color: #800000">‚îÇ</span>
<span style="color: #800000; text-decoration-color: #800000">‚îÇ</span> ‚Ä¢ King Vajiralongkorn is also known as Rama X.                                                                  <span style="color: #800000; text-decoration-color: #800000">‚îÇ</span>
<span style="color: #800000; text-decoration-color: #800000">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>
</pre></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #008000; text-decoration-color: #008000">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">Refined Response</span><span style="color: #008000; text-decoration-color: #008000"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>
<span style="color: #008000; text-decoration-color: #008000">‚îÇ</span> Queen Suthida Bajrasudhabimalalakshana, the current and influential Queen of Thailand, began her career as a    <span style="color: #008000; text-decoration-color: #008000">‚îÇ</span>
<span style="color: #008000; text-decoration-color: #008000">‚îÇ</span> flight attendant for Thai Airways International. Her diverse background also includes a military role, as she   <span style="color: #008000; text-decoration-color: #008000">‚îÇ</span>
<span style="color: #008000; text-decoration-color: #008000">‚îÇ</span> was made a full General in 2017. She officially married King Vajiralongkorn on May 1, 2019, becoming Queen just <span style="color: #008000; text-decoration-color: #008000">‚îÇ</span>
<span style="color: #008000; text-decoration-color: #008000">‚îÇ</span> days before his official coronation.                                                                            <span style="color: #008000; text-decoration-color: #008000">‚îÇ</span>
<span style="color: #008000; text-decoration-color: #008000">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="3.-Evaluate-Hallucination-Detection-Performance">
<h2>3. Evaluate Hallucination Detection Performance<a class="headerlink" href="#3.-Evaluate-Hallucination-Detection-Performance" title="Link to this heading">#</a></h2>
<p>To evaluate hallucination detection performance, we ‚Äògrade‚Äô the atomic claims in the responses against an answer key. Here, we use UQLM‚Äôs out-of-the-box <code class="docutils literal notranslate"><span class="pre">FactScoreGrader</span></code>, which can be used with <a class="reference external" href="https://js.langchain.com/docs/integrations/chat/">LangChain Chat Model</a>. <strong>If you are using your own prompts/questions, be sure to update the grading method accordingly</strong>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up the LLM grader</span>
<span class="n">grader</span> <span class="o">=</span> <span class="n">FactScoreGrader</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">gemini_flash</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Before grading, we need to have claims formatted in list of lists where each interior list corresponds to a generated response.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert claims to list of lists</span>
<span class="n">claims_data_lists</span> <span class="o">=</span> <span class="n">claims_dicts_to_lists</span><span class="p">(</span><span class="n">result_df</span><span class="o">.</span><span class="n">claims_data</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># grade original responses against the answer key using the grader</span>
<span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;claim_grades&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="k">await</span> <span class="n">grader</span><span class="o">.</span><span class="n">grade_claims</span><span class="p">(</span><span class="n">claim_sets</span><span class="o">=</span><span class="n">claims_data_lists</span><span class="p">[</span><span class="s2">&quot;claim&quot;</span><span class="p">],</span> <span class="n">answers</span><span class="o">=</span><span class="n">factscore</span><span class="p">[</span><span class="s2">&quot;wikipedia_text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
<span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">factscore</span><span class="p">[</span><span class="s2">&quot;wikipedia_text&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>response</th>
      <th>noncontradiction</th>
      <th>claims_data</th>
      <th>refined_response</th>
      <th>refined_noncontradiction</th>
      <th>claim_grades</th>
      <th>answer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Tell me a bio of Suthida within 100 words.\n</td>
      <td>Queen Suthida Bajrasudhabimalalakshana is the ...</td>
      <td>0.872727</td>
      <td>[{'claim': 'Queen Suthida Bajrasudhabimalalaks...</td>
      <td>Queen Suthida Bajrasudhabimalalakshana, the cu...</td>
      <td>0.985608</td>
      <td>[True, True, True, True, False, False, True, F...</td>
      <td>Suthida Bajrasudhabimalalakshana (Thai: ‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Tell me a bio of Miguel √Ångel F√©lix Gallardo w...</td>
      <td>Miguel √Ångel F√©lix Gallardo, known as "El Padr...</td>
      <td>0.922575</td>
      <td>[{'claim': 'Miguel √Ångel F√©lix Gallardo was kn...</td>
      <td>Miguel √Ångel F√©lix Gallardo, famously known as...</td>
      <td>0.973158</td>
      <td>[True, True, True, True, True, True, True, Tru...</td>
      <td>Miguel √Ångel F√©lix Gallardo (born January 8, 1...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Tell me a bio of Iggy Azalea within 100 words.\n</td>
      <td>Amethyst Amelia Kelly, known professionally as...</td>
      <td>0.895390</td>
      <td>[{'claim': 'Amethyst Amelia Kelly is known pro...</td>
      <td>Amethyst Amelia Kelly, known professionally as...</td>
      <td>0.986233</td>
      <td>[True, True, True, False, True, True, True, Tr...</td>
      <td>Amethyst Amelia Kelly (born 7 June 1990), know...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Tell me a bio of Fernando da Costa Novaes with...</td>
      <td>Fernando da Costa Novaes (1942-2004) was a hig...</td>
      <td>0.797684</td>
      <td>[{'claim': 'Fernando da Costa Novaes was born ...</td>
      <td>Fernando da Costa Novaes was a highly influent...</td>
      <td>0.966738</td>
      <td>[False, True, False, False, False, False, Fals...</td>
      <td>Fernando da Costa Novaes (April 6, 1927 ‚Äì Marc...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Tell me a bio of Jan Zamoyski within 100 words.\n</td>
      <td>Jan Zamoyski (1542‚Äì1605) was a preeminent Poli...</td>
      <td>0.947813</td>
      <td>[{'claim': 'Jan Zamoyski was born in 1542.', '...</td>
      <td>Jan Zamoyski, born in 1542 and dying in 1605, ...</td>
      <td>0.978016</td>
      <td>[True, True, True, True, True, True, True, Tru...</td>
      <td>Jan Sariusz Zamoyski (Latin: Ioannes Zamoyski ...</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">all_claim_scores</span><span class="p">,</span> <span class="n">all_claim_grades</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">)):</span>
    <span class="n">all_claim_scores</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">claims_data_lists</span><span class="p">[</span><span class="s2">&quot;noncontradiction&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
    <span class="n">all_claim_grades</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;claim_grades&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;Baseline LLM accuracy: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_claim_grades</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Baseline LLM accuracy: 0.6322751322751323
</pre></div></div>
</div>
<p>To evaluate fine-grained hallucination detection performance, we compute AUROC of claim-level hallucination detection. Below, we plot the ROC curve and report these results.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">all_claim_grades</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">all_claim_scores</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">all_claim_grades</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">all_claim_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;ROC curve (AUC = </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;navy&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Receiver Operating Characteristic (ROC) Curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_long_text_qa_demo_29_0.png" src="../../_images/_notebooks_examples_long_text_qa_demo_29_0.png" />
</div>
</div>
<p>Lastly, we evaluate the gains from uncertainty-aware decoding (UAD) by measuring the factual precision over claims at various filtering thresholds.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model_accuracies</span><span class="p">(</span><span class="n">scores</span><span class="o">=</span><span class="n">all_claim_scores</span><span class="p">,</span> <span class="n">correct_indicators</span><span class="o">=</span><span class="n">all_claim_grades</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;LLM Accuracy by Claim Confidence Threshold&quot;</span><span class="p">,</span> <span class="n">display_percentage</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_long_text_qa_demo_32_0.png" src="../../_images/_notebooks_examples_long_text_qa_demo_32_0.png" />
</div>
</div>
<p>Since, we have selected a threshold of 0.85, we can measure LLM accuracy with and without UAD.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.85</span>
<span class="n">filtered_grades</span><span class="p">,</span> <span class="n">filtered_scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">grade</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">all_claim_grades</span><span class="p">,</span> <span class="n">all_claim_scores</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">thresh</span><span class="p">:</span>
        <span class="n">filtered_grades</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grade</span><span class="p">)</span>
        <span class="n">filtered_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Baseline LLM factual precision: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_claim_grades</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;UAD-Improved LLM factual precision: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">filtered_grades</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Baseline LLM factual precision: 0.6713091922005571
UAD-Improved LLM factual precision: 0.7306273062730627
</pre></div></div>
</div>
</section>
<section id="4.-Scorer-Definitions">
<h2>4. Scorer Definitions<a class="headerlink" href="#4.-Scorer-Definitions" title="Link to this heading">#</a></h2>
<p>Long-form uncertainty quantification implements a three-stage pipeline after response generation:</p>
<ol class="arabic simple">
<li><p>Response Decomposition: The response <span class="math notranslate nohighlight">\(y\)</span> is decomposed into units (claims or sentences), where a unit as denoted as <span class="math notranslate nohighlight">\(s\)</span>.</p></li>
<li><p>Unit-Level Confidence Scoring: Confidence scores are computed using function <span class="math notranslate nohighlight">\(c_g(s;\cdot) \in [0, 1]\)</span>. Higher scores indicate greater likelihood of factual correctness. Units with scores below threshold <span class="math notranslate nohighlight">\(\tau\)</span> are flagged as potential hallucinations.</p></li>
<li><p>Response-Level Aggregation: Unit scores are combined to provide an overall response confidence.</p></li>
</ol>
<p>The Claim-QA approach demonstrated here is adapted from <a class="reference external" href="https://www.nature.com/articles/s41586-024-07421-0">Farquhar et al., 2024</a>. It uses an LLM to convert each unit (sentence or claim) into a question for which that unit would be the answer. The method measures consistency across multiple responses to these questions, effectively applying standard black-box uncertainty quantification to those sampled responses to the unit questions. Formally, a claim-QA scorer <span class="math notranslate nohighlight">\(c_g(s;\cdot)\)</span> is
defined as follows:</p>
<div class="math notranslate nohighlight">
\[c_g(s; y_0^{(s)}, \mathbf{y}^{(s)}_{\text{cand}}) = \frac{1}{m} \sum_{j=1}^m \eta(y_0^{(s)}, y_j^{(s)})\]</div>
<p>where <span class="math notranslate nohighlight">\(y_0^{(s)}\)</span> is the original unit response, <span class="math notranslate nohighlight">\(\mathbf{y}^{(s)}_{\text{cand}} = {y_1^{(s)}, ..., y_m^{(s)}}\)</span> are <span class="math notranslate nohighlight">\(m\)</span> candidate responses to the unit‚Äôs question, and <span class="math notranslate nohighlight">\(\eta\)</span> is a consistency function such as contradiction probability, cosine similarity, or BERTScore F1. Semantic entropy, which follows a slightly different functional form, can also be used to measure consistency.</p>
<p>¬© 2025 CVS Health and/or one of its affiliates. All rights reserved.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#üìä-What-You'll-Do-in-This-Demo">üìä What You‚Äôll Do in This Demo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#‚öñÔ∏è-Advantages-&amp;-Limitations">‚öñÔ∏è Advantages &amp; Limitations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#1.-Set-up-LLM-and-Prompts">1. Set up LLM and Prompts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#2.-Generate-LLM-Responses-and-Claim/Sentence-Level-Confidence-Scores">2. Generate LLM Responses and Claim/Sentence-Level Confidence Scores</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#LongTextQA()---Generate-long-text-LLM-responses,-decompose-into-claims-or-sentences,-create-questions-for-which-those-claims-are-the-answers,-and-measure-consistency-in-LLM-responses-to-those-questions."><code class="docutils literal notranslate"><span class="pre">LongTextQA()</span></code> - Generate long-text LLM responses, decompose into claims or sentences, create questions for which those claims are the answers, and measure consistency in LLM responses to those questions.</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#üìã-Class-Attributes">üìã Class Attributes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#üîç-Parameter-Groups">üîç Parameter Groups</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#üîÑ-Class-Methods">üîÑ Class Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#Response-refinement">Response refinement</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#3.-Evaluate-Hallucination-Detection-Performance">3. Evaluate Hallucination Detection Performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#4.-Scorer-Definitions">4. Scorer Definitions</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/_notebooks/examples/long_text_qa_demo.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2025, CVS Health.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>