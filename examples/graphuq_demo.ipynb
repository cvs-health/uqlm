{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2a2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphUQ Demo - Bipartite Graph-based Uncertainty Quantification\n",
    "# This notebook demonstrates the GraphUQScorer for claim-level uncertainty quantification\n",
    "\n",
    "from uqlm.longform.black_box.graphuq import GraphUQScorer\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import logging\n",
    "\n",
    "# Configure logging to see debug output\n",
    "logging.basicConfig(level=logging.WARNING, format=\"%(name)s - %(levelname)s - %(message)s\")\n",
    "logging.getLogger(\"uqlm.longform.black_box.graphuq\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96199003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uqlm.longform.black_box.graphuq - INFO - Initialized GraphUQScorer\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM and GraphUQScorer\n",
    "judge_llm = ChatVertexAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "nli_llm = ChatVertexAI(model=\"gemini-2.5-flash\", temperature=0, logprobs=True)\n",
    "\n",
    "graphuq_scorer = GraphUQScorer(judge_llm=judge_llm, nli_llm=nli_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test data (2 queries)\n",
    "responses = [\n",
    "    [\n",
    "        \"The sky is blue. The grass is green.\",\n",
    "        \"The sky is blue. The grass is red.\",\n",
    "        \"The sky is blue.\",\n",
    "        \"The grass is red. The ocean is pink.\",\n",
    "    ],\n",
    "    [\n",
    "        \"She likes to play basketball and soccer.\",\n",
    "        \"She likes to play basketball and tennis.\",\n",
    "        \"She likes to play basketball and soccer.\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "original_claim_set = [\n",
    "    [\"The sky is blue.\", \"The grass is green.\"],\n",
    "    [\"She likes to play basketball.\", \"She likes to play soccer.\"],\n",
    "]\n",
    "\n",
    "sampled_claim_sets = [\n",
    "    [\n",
    "        [\"The ocean is pink.\", \"The grass is red.\"],\n",
    "        [\"The sky is blue.\", \"The grass is red.\"],\n",
    "        [\"The sky is blue.\"],\n",
    "    ],\n",
    "    [\n",
    "        [\"She likes to play basketball.\", \"She likes to play tennis.\"],\n",
    "        [\"She likes to play basketball.\", \"She likes to play soccer.\"],\n",
    "    ],\n",
    "]\n",
    "\n",
    "entailment_score_sets = [{\"the sky is blue.\":[1,1,1,1,1,0,1,1,1,1],\n",
    "\"the ocean is pink.\":[0,0,0,0,0,0,0,1,0,0]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a891181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uqlm.longform.black_box.graphuq - DEBUG - Starting evaluation for 2 response sets.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run GraphUQ evaluation with probability-weighted edges (0.0 to 1.0)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m result_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m graphuq_scorer\u001b[38;5;241m.\u001b[39ma_evaluate(\n\u001b[1;32m      4\u001b[0m     responses,\n\u001b[1;32m      5\u001b[0m     original_claim_set,\n\u001b[1;32m      6\u001b[0m     sampled_claim_sets,\n\u001b[1;32m      7\u001b[0m     use_entailment_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Use entailment probabilities as edge weights; requires nli model to return probs\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     show_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# save_graph_path=\"graphuq_probability.html\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbability mode results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result_prob:\n",
      "File \u001b[0;32m~/Documents/GitHub/uqlm_dskar/uqlm/longform/black_box/graphuq.py:72\u001b[0m, in \u001b[0;36mGraphUQScorer.a_evaluate\u001b[0;34m(self, response_sets, original_claim_sets, sampled_claim_sets, entailment_score_sets, progress_bar, save_graph_path, show_graph, use_entailment_prob, edge_weight_threshold)\u001b[0m\n\u001b[1;32m     68\u001b[0m     progress_task \u001b[38;5;241m=\u001b[39m progress_bar\u001b[38;5;241m.\u001b[39madd_task(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Scoring claims/sentences with GraphUQ...\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(response_sets))\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Create tasks for all response sets to run concurrently\u001b[39;00m\n\u001b[1;32m     71\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_single_response_set(i, responses, original_claim_set, sampled_claim_set, entailment_score_set, use_entailment_prob, edge_weight_threshold, save_graph_path, show_graph, progress_bar, progress_task) \u001b[38;5;28;01mfor\u001b[39;00m i, (responses, original_claim_set, sampled_claim_set, entailment_score_set) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse_sets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_claim_sets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_claim_sets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentailment_score_sets\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     73\u001b[0m ]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Run all tasks concurrently\u001b[39;00m\n\u001b[1;32m     76\u001b[0m claim_score_lists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Run GraphUQ evaluation with probability-weighted edges (0.0 to 1.0)\n",
    "\n",
    "result_prob = await graphuq_scorer.a_evaluate(\n",
    "    responses,\n",
    "    original_claim_set,\n",
    "    sampled_claim_sets,\n",
    "    use_entailment_prob=True,  # Use entailment probabilities as edge weights; requires nli model to return probs\n",
    "    show_graph=True,\n",
    "    # save_graph_path=\"graphuq_probability.html\"\n",
    ")\n",
    "\n",
    "print(\"Probability mode results:\")\n",
    "for res in result_prob:\n",
    "    print(res.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348f0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uqlm-uJgWJAxm-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
